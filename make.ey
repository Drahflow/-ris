#!./loaded

"xml.ey" include

"https://ratsinfo.braunschweig.de/bi" ==:BASEURL
"/opt/forallris" ==:DOCUMENTSTORAGE
DOCUMENTSTORAGE "/cookies.txt" cat ==:COOKIES

sys "+" via +linux "++" via

{ { txt .produce .hu _ len 2 eq "%" "%0" ? -01 cat } each } /pctEncode deffst
{ [ -01 { ==c [
  { c 128 lt } { c }
  { 1 } { 194 c 64 band 1 0 ? add  c 64 bnot band }
] conds } each ] str .fromArray } /iso2utf8 deffst
{ [ -01 { 32 max } each ] str .fromArray } /sanitize deffst
{ [ -01 { ==c [
  { c 47 eq } { 95 }
  { c 33 ge } { c }
  { 1 } { 95 }
] conds } each ] str .fromArray } /sanitizeFilename deffst
{ ==l ==s s len l gt { l s str .prefix } { s } ? * } /truncateTo deffst

{
  { "> " +out .writeall 30 +in .read "([0-9]+)" regex not } { "Bitte Zahl eingeben" dump } loop
  txt .consume .u
} /inputNumber deffst

{ "\0" cat ++stat -01 -- 0 eq } /fileExists deffst
{ "\0" cat -01 "\0" cat -01 ++symlink } /symlink deffst
{ "\0" cat ++unlink } /unlink deffst
{ COOKIES unlink } /killCookies deffst
{ [ } "[|" deffd { ] |cat fold } "|]" deffd

{ "^(..)-(.*)" regex not { "Dokumentnummer enthält keinen -." die } rep
  ==year ==rest
  [| DOCUMENTSTORAGE "/" year |] "\0" cat 511 ++mkdir --
  [| DOCUMENTSTORAGE "/" year "/" year "-" rest ".pdf" |]
} /storageFilename deffst
{ "_([0-9][0-9]-[0-9-]+)_" regex } /extractNumber deffst

{ sys .file -010 .open } /open deffd

{
  crypt .sha512 .hex _ ==hash "^(..)(..)(..)" regex -- ==dirA ==dirB ==dirC
  [| DOCUMENTSTORAGE "/" dirA "/" dirB "/" dirC "/" hash |]
} /cacheFilename deffst

{ ==identifier =*upstream
  identifier crypt .sha512 .hex _ ==hash "^(..)(..)(..)" regex -- ==dirA ==dirB ==dirC
  [| DOCUMENTSTORAGE "/" dirA "/" dirB "/" dirC "/" hash |] ==cacheFile

  cacheFile fileExists {
    [| "Serving from cache file: " cacheFile |] dump
    cacheFile open
  } {
    [| DOCUMENTSTORAGE "/" dirA |] "\0" cat 511 ++mkdir --
    [| DOCUMENTSTORAGE "/" dirA "/" dirB |] "\0" cat 511 ++mkdir --
    [| DOCUMENTSTORAGE "/" dirA "/" dirB "/" dirC |] "\0" cat 511 ++mkdir --

    [| "Fetching from upstream: " identifier " to " cacheFile |] dump
    cacheFile upstream

    cacheFile fileExists {
      cacheFile open
    } {
      <
        { "/dev/null" open } =*empty
      > ???io.web.fetch
    } ? *
  } ? *
} /cache deffst

{ ==url
  { ==cacheFile
    { [| "wget -O '" cacheFile "' '" BASEURL url "'" |] +shell } +spawn ":" via
    { dump } :err .eachLine :wait --
  } url cache
} /fetch deffst

{ ==name name "|" | name |defvst } ">=" defq
{ ==name "}" | * ==f name "|" | f "*" | name "=" | } "}=" defq

{ "/si010_e.asp" fetch ":" via # /ri/si010_e.asp?MM=5&amp;YY=2015
  "??" ==weekday "??" ==monthday "??:??" ==time
  [
    { ==line [
      { line "<td class=\"text2\" width=\"20\">(..)</td><td class=\"text2\" width=\"20\">(&nbsp;&nbsp;)?([^<]+)</td>" regex }' {
        =weekday -- =monthday
      }
      { line "<td class=\"text2\">(..:..)&nbsp;</td>" regex }' {
        =time
      }
      { line "<td><a href=\"to010.asp\\?SILFDNR=([^\"]+)\">(<b>)?([^<]+)(</b>)?</a></td>" regex }' {
        < ==id -- iso2utf8 sanitize ==title -- >=weekday >=monthday >=time >
      }
    ] conds } :eachLine :close
  ]
} /calendar deffst

{ ==str
  { str "^(.*)<a [^>]+>(.*)$" regex } { -01 cat =str } loop
  { str "^(.*)</a>(.*)$" regex } { -01 cat =str } loop
  str
} /stripLinkParts deffst

{ [| "/to010.asp?SILFDNR=" -102 |] fetch ":" via
  { "?" ==maybeTitle "?" ==title "?" ==position "?" ==id "?" ==number }'
    _ * =*reset
  [
    { ==line [
      { line "<!--[0-9]+ -->" regex }' { maybeTitle iso2utf8 sanitize =title }
      { line stripLinkParts "<td>([^<]+)</td>" regex }' { =maybeTitle }
      { line stripLinkParts "<td>([^<]+)$" regex }' { =maybeTitle }
      { line stripLinkParts "^([^<]+)$" regex }' { { -01 cat }=maybeTitle }
      { line stripLinkParts "^([^<]+)</td>" regex }' { { -01 cat }=maybeTitle }
      { line "<td class=\"text4\" nowrap=\"nowrap\"><a href=\"[^\"]+\" title=\"[^\"]+\">.&nbsp;([0-9.]+)</a></td>" regex }' {
        =position
      }
      { line "<td class=\"text4\" nowrap=\"nowrap\"><span style=\"background-color:#[^\"]+\" title=\"[^\"]+\"><a href=\"[^\"]+\" title=\"[^\"]+\">.&nbsp;([0-9.]+)</a></span></td>" regex }' {
        =position
      }
      { line "<td nowrap=\"nowrap\"><a href=\"vo020.asp\\?VOLFDNR=([^\"]+)\">(<b>)?([^<]+)(</b>)?</a></td>" regex }' {
        =id -- =number --
      }
      { line "	</tr>" regex position "?" neq and }' {
        < number "?" neq ==hasDocument >=id >=number >=title >=position >
        reset
      }
    ] conds } :eachLine :close
  ]
} /agenda deffst

[|
  "<form action=\"do027.asp\" method=\"post\" style=\"margin:0\" *>"
  "<input type=\"hidden\" name=\"DOLFDNR\" value=\"(\\d+)\" */>"
  "<input type=\"hidden\" name=\"options\" value=\"64\" */>"
  "<input type=\"hidden\" name=\"typ\" value=\"130\" */>"
  "<input type=\"submit\" class=\"il2_p\" value=\"Vorlage-Sammeldokument\" title=\"Vorlage-Sammeldokument\" */>"
  "</form>"
|] enregex =*:DOCUMENTLINKREGEX

{ [| "/vo020.asp?VOLFDNR=" -102 |] _ fetch ":" via
                                     BASEURL -01 cat ==url
  [ {
    DOCUMENTLINKREGEX { _ dump ==id 
      { ==cacheFile
        # grab a session cookie -.-
        {
          [| "wget -O /dev/null --save-cookies '" COOKIES "' --keep-session-cookies '" url "'" |] +shell
        } +spawn "::" via
        { dump } ::err .eachLine ::wait --

        {
          [|
            "wget -O '" cacheFile "' "
            "--load-cookies '" COOKIES "' "
            "'" BASEURL "/do027.asp' "
            "--post-data='DOLFDNR=" id "&options=64&typ=130'"
          |] +shell
        } +spawn "::" via
        { dump } ::err .eachLine ::wait --
      } [| "/document/" id |] cache
    } rep
  } :eachLine :close ] ==docs

  docs len 1 neq {
    <
      { docs { .close } '*0. "/dev/null" open } =*empty
    > ???io.web.pattern
  } rep

  0 docs *
} /fetchDocument deffst

{ ==l { _ len l lt } { "0" -01 cat } loop } '01.0 /padTo deffst

{ ":" via
  [|
    [ :position { _ "^([^.]*)\\.(.*)" regex } { -012 -- } loop ] 3 padTo { "." -201 cat cat } fold
    "_" :number "_"
    :title sanitizeFilename 60 truncateTo
    ".pdf"
  |]
} /agendaFilename deffst

{ ==title
  [| "<html><head><title>" title "</title></head><body>" |]
} /htmlHeader deffst

{
  [| "</body></html>" |]
} /htmlFooter deffst

<
  { ==target ==text
    [| "<a href=\"" target "\">" text "</a>" |]
  } /a deffst
  { "<br>" } /br deffst
  { ==items
    [|
      "<ul>"
      items { "<li>" -01 "</li>" } each
      "</ul>"
    |]
  } /ul deffst
  { ==rows
    [|
      "<table>"
      rows { ==cols
        "<tr>"
        cols {
          "<td>" -01 "</td>"
        } each
        "</tr>"
      } each
      "</table>"
    |]
  } /table deffst
> "<>" via

{ "=>" via
  [|
    "Sitzungsübersicht" htmlHeader
    [
      calendar { ":" via
        [| :monthday ". " :time " - " :title |] [| "/agenda/" :id |] <>a
      } each
    ] <>ul
    htmlFooter
  |] =>okHtml
} /showCalendar deffst

{ "=>" via ==id
  [|
    "Tagesordnung" htmlHeader
    [
      id agenda { ":" via
        [
          :position :number
          :title :hasDocument { [| "/editor/" :id |] <>a } rep
        ]
      } each
    ] <>table
    htmlFooter
  |] =>okHtml
} /showAgenda deffst

{ "=>" via ==id
  VIEWER =>okHtml
} /showEditor deffst

{ "=>" via fetchDocument ":" via
  [|
    { 8192 :read _ "" neq } { } loop :close
  |] "application/pdf" =>ok
} /showDocument deffst

{ =*p # ==start
  { _ p { _ } rep
      _ .?'children { .children |recurse each } { -- } ? *
  } /recurse deffst
  [ -01 recurse ]
} /selectNodes deffst

{
  [ -01 { ==c
    [
      { c 38 eq }' { "&amp;" { } each }'
      { c 60 eq }' { "&lt;" { } each }'
      { c 62 eq }' { "&gt;" { } each }'
    ] conds
  } each ] str .fromArray
} /escapeXML deffst

{ ==pages ":" via
  "<?xml version=\"1.0\" standalone=\"no\"?>\n" :writeall
  "<xournal version=\"0.4.7\">\n" :writeall
  "<title>Xournal document - see http://math.mit.edu/~auroux/software/xournal/</title>\n" :writeall

  1 ==firstPage
  pages { ==page [|
    "<page width=\"" /width page .attr * "\" height=\"" /height page .attr * "\">\n"
    page { .name "background" eq } selectNodes 0 -01 * ==background
    "<background type=\"pdf\" "
      firstPage {
        0 =firstPage
        "domain=\"" /domain background .attr * "\" filename=\"" /filename background .attr * "\" "
      } rep
      "pageno=\"" /pageno background .attr * "\" "
    "/>\n"
    page { .name "layer" eq } selectNodes { ==layer
      "<layer>\n"
      layer { .name "" neq } selectNodes { ==item
        [
          { item .name "stroke" eq } {
            "<stroke tool=\"" /tool item .attr * "\" color=\"" /color item .attr * "\" width=\"" /width item .attr * "\">"
            item .children { .text } each
            "</stroke>\n"
          }
          { item .name "text" eq } {
            "<text font=\"" /font item .attr *
              "\" size=\"" /size item .attr * "\" x=\"" /x item .attr * "\" y=\"" /y item .attr *
              "\" color=\"" /color item .attr * "\">"
            [| item .children { .text } each |] escapeXML
            "</text>\n"
          }
        ] conds
      } each
      "</layer>\n"
    } each
    "</page>\n"
  |] :writeall } each

  "</xournal>\n" :writeall
} /writeXournal deffst

{ "=>" via ==id [| "/comments/" id |] ==identifier
  "Adding comment" dump
  =>args .page dump
  =>body dump

  # FIXME: input validation .page, .width, .height
  =>args .page txt .consume .u ==changedPage

  [
    { =>body "<stroke tool=\"([^\"]+)\" color=\"([^\"]+)\" width=\"([0-9.]+)\">(\n[0-9. ]+\n)</stroke>" regex } {
      <
        "stroke" ==name map ==attr
        /tool attr =[]
        /color attr =[]
        /width attr =[]

        < "" ==name ==text > [ -01 ] ==children
      >
    }
    { 1 } {
      "Invalid body - ignoring request." dump
      < "" ==name "" ==text >
    }
  ] conds ==newElement

  { ==cacheFile
    sys .file ":" via :creating :writeonly cacheFile :open
    EMPTYXOJ :writeall
    :close
  } identifier cache ":" via
  
  [|
    { 8192 :read _ "" neq } { } loop :close
  |] xml .parse { .name "page" eq } selectNodes ==pages

  pages dump

  { pages len changedPage lt } {
    pages [
      <
        "page" ==name map ==attr
        =>args .width /width attr =[] # FIXME: get this number from somewhere
        =>args .height /height attr =[] # FIXME: get this number from somewhere
        [
          <
            "background" ==name map ==attr
            "pdf" /type attr =[]
            pages len 1 add txt .produce .u /pageno attr =[]
            pages len not {
              "absolute" /domain attr =[]
              "/dev/null" /filename attr =[]
            } rep
          >
          <
            "layer" ==name map ==attr
            [ < "" ==name "" ==text map ==attr > ] ==children
            { =children } =*setChildren
          >
        ] ==children
      >
    ] cat =pages
  } loop

  changedPage 1 sub pages * { .name "layer" eq } selectNodes 0 -01 * _ .children [ newElement ] cat
                                                                       -01 .setChildren

  "Rewriting: " identifier cacheFilename cat dump
  sys .file _ ":" via :truncating :writeonly identifier cacheFilename :open
              pages writeXournal :close

  "Added." "text/plain" =>ok
} /addComments deffst

{ "=>" via ==id
  [| "/comments/" id |] ==identifier
  identifier cacheFilename fileExists {
    { "Cache file should have existed." die } identifier cache ":" via

    [|
      { 8192 :read _ "" neq } { } loop :close
    |]
  } {
    EMPTYXOJ
  } ? *
  "application/xournal" =>ok
  # XOJ "application/xournal" =>ok
} /showComments deffst

{ "=>" via
  [|
    "Seite nicht gefunden" htmlHeader
    "Diese Seite existiert nicht"
    htmlFooter
  |] =>failHtml
} /showNotFound deffst

{ open ":" via
  [| { 8192 :read _ "" neq } { } loop :close |]
} /slurp deffd

"pdf.js" slurp ==:PDFJS
"pdf.worker.js" slurp ==:PDFJSWORKER
"pdf.js.upstream/build/generic/web/compatibility.js" slurp ==:COMPATIBILITYJS
"pdf.js.upstream/build/generic/web/l10n.js" slurp ==:LOCALIZATIONJS
"viewer.properties" slurp ==:LOCALE
"viewer.js" slurp ==:VIEWERJS
"viewer.css" slurp ==:VIEWERCSS
"viewer.html" slurp ==:VIEWER
map ==:PNGS map ==:GIFS
"pdf.js.upstream/build/generic/web/images/*.png" sys .glob { _ dump ==img
  img slurp "pdf.js.upstream/build/generic/web" len img str .postfix PNGS =[]
} each
"pdf.js.upstream/build/generic/web/images/*.gif" sys .glob { _ dump ==img
  img slurp "pdf.js.upstream/build/generic/web" len img str .postfix GIFS =[]
} each

"test.pdf.xoj.gunz" slurp ==:XOJ
"empty.xoj.gunz" slurp ==:EMPTYXOJ

{
  net .alg .httpServer "+" via
  { 8091 } +port
  {
    <
      { "text/html; charset=utf-8;" ok } =*okHtml
      { "text/html; charset=utf-8;" fail } =*failHtml
    >' _ ":_" defvst ":" via
    :url dump
    [
      { :url "/" eq } { :_ showCalendar }
      { :url "/agenda/(\\d+)" regex } { :_ showAgenda }
      { :url "/editor/(\\d+)" regex } { :_ showEditor }
      { :url "/document/(\\d+)" regex } { :_ showDocument }
      { :url "/comments/(\\d+)/add" regex } { :_ addComments }
      { :url "/comments/(\\d+)" regex } { :_ showComments }
      { :url "/pdf.js" eq } { PDFJS "text/javascript; charset=utf-8;" :ok }
      { :url "/pdf.worker.js" eq } { PDFJSWORKER "text/javascript; charset=utf-8;" :ok }
      { :url "/compatibility.js" eq } { COMPATIBILITYJS "text/javascript; charset=utf-8;" :ok }
      { :url "/l10n.js" eq } { LOCALIZATIONJS "text/javascript; charset=utf-8;" :ok }
      { :url "/locale.properties" eq } { LOCALE "application/l10n" :ok }
      { :url "/viewer.js" eq } { VIEWERJS "text/javascript; charset=utf-8;" :ok }
      { :url "/viewer.css" eq } { VIEWERCSS "text/css; charset=utf-8;" :ok }
      { :url PNGS .has } { :url PNGS * "image/png" :ok }
      { :url GIFS .has } { :url GIFS * "image/gif" :ok }
      { 1 } { :_ showNotFound }
    ] conds
  } +request
  { 64 1024 1024 mul mul } +outputBufferLimit
  { 1024 1024 mul } +inputBufferLimit
  +run
} /forallris sys .freeze

# vim: syn=elymas
