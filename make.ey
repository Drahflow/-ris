#!./loaded

"xml.ey" include

"https://ratsinfo.braunschweig.de/bi" ==:BASEURL
"/opt/forallris/cache" ==:CACHESTORAGE
"/opt/forallris/comments" ==:COMMENTSSTORAGE
CACHESTORAGE "/cookies.txt" cat ==:COOKIES

sys "+" via +linux "++" via

{ { txt .produce .hu _ len 2 eq "%" "%0" ? -01 cat } each } /pctEncode deffst
{ [ -01 { ==c [
  { c 128 lt } { c }
  { 1 } { 194 c 64 band 1 0 ? add  c 64 bnot band }
] conds } each ] str .fromArray } /iso2utf8 deffst
{ [ -01 { 32 max } each ] str .fromArray } /sanitize deffst
{ [ -01 { ==c [
  { c 47 eq } { 95 }
  { c 33 ge } { c }
  { 1 } { 95 }
] conds } each ] str .fromArray } /sanitizeFilename deffst
{ ==l ==s s len l gt { l s str .prefix } { s } ? * } /truncateTo deffst

{
  { "> " +out .writeall 30 +in .read "([0-9]+)" regex not } { "Bitte Zahl eingeben" dump } loop
  txt .consume .u
} /inputNumber deffst

{ "\0" cat ++stat -01 -- 0 eq } /fileExists deffst
{ "\0" cat -01 "\0" cat -01 ++symlink } /symlink deffst
{ "\0" cat ++unlink } /unlink deffst
{ COOKIES unlink } /killCookies deffst
{ [ } "[|" deffd { ] |cat fold } "|]" deffd

{ "_([0-9][0-9]-[0-9-]+)_" regex } /extractNumber deffst

{ sys .file -010 .open } /open deffd

{ ==storage
  crypt .sha512 .hex _ ==hash "^(..)(..)(..)" regex -- ==dirA ==dirB ==dirC
  [| storage "/" dirA "/" dirB "/" dirC "/" hash |]
} /storageFilename deffst

{ CACHESTORAGE storageFilename } /cacheFilename deffst
{ COMMENTSSTORAGE storageFilename } /commentsFilename deffst

{ ==storage ==identifier =*upstream
  identifier crypt .sha512 .hex _ ==hash "^(..)(..)(..)" regex -- ==dirA ==dirB ==dirC
  [| storage "/" dirA "/" dirB "/" dirC "/" hash |] ==storageFile

  storageFile fileExists {
    [| "Serving from storage file: " storageFile |] dump
    storageFile open
  } {
    [| storage |] "\0" cat 511 ++mkdir --
    [| storage "/" dirA |] "\0" cat 511 ++mkdir --
    [| storage "/" dirA "/" dirB |] "\0" cat 511 ++mkdir --
    [| storage "/" dirA "/" dirB "/" dirC |] "\0" cat 511 ++mkdir --

    [| "Fetching from upstream: " identifier " to " storageFile |] dump
    storageFile upstream

    storageFile fileExists {
      storageFile open
    } {
      <
        { "/dev/null" open } =*empty
      > ???io.web.fetch
    } ? *
  } ? *
} /storage deffst

{ CACHESTORAGE storage } /cache deffst
{ COMMENTSSTORAGE storage } /comments deffst

{ ==url
  { ==cacheFile
    { [| "wget -O '" cacheFile "' '" BASEURL url "'" |] +shell } +spawn ":" via
    { dump } :err .eachLine :wait --
  } url cache
} /fetch deffst

{ ==name name "|" | name |defvst } ">=" defq
{ ==name "}" | * ==f name "|" | f "*" | name "=" | } "}=" defq

{ ==year ==month
  [| "/si010_e.asp?MM=" month "&amp;YY=" year |] fetch ":" via # /ri/si010_e.asp?MM=5&amp;YY=2015

  "??" ==weekday "??" ==monthday "??:??" ==time 0 ==past
  [
    1 neg ==col
    { ==line [
      { 5 line str .prefix "	<tr " eq { line "<tr class=\"zl\\d+\" valign=\"top\">" regex } { 0 } ? * }' {
        0 =col
      }
      { col 0 ge { line { "<td[ >](.*)" regex }' { col 1 add =col }' loop } rep 0 }' { }
      { col 2 eq { line "<td class=\"text2\" width=\"20\">(..)</td><td class=\"text2\" width=\"20\">(&nbsp;&nbsp;)?([^<]+)</td>" regex } { 0 } ? * }' {
        =weekday -- =monthday
      }
      { col 3 eq { line "<td class=\"text2\">(..:..)( - ..:..)?&nbsp;</td>" regex } { 0 } ? * }' {
        =time "" neq =past
      }
      { col 6 eq { line "<td><a href=\"to010.asp\\?SILFDNR=([^\"]+)\">(<b>)?([^<]+)(</b>)?</a></td>" regex } { 0 } ? * }' {
        < ==id -- iso2utf8 sanitize ==title -- >=weekday >=monthday >=time >=past >
      }
      { col 6 eq { line "<td>([^<]+)</td>" regex } { 0 } ? * }' {
        < "" ==id iso2utf8 sanitize ==title >=weekday >=monthday >=time >=past >
      }
    ] conds } :eachLine :close
  ]
} /calendar deffst

{ ==str
  { str "^(.*)<a [^>]+>(.*)$" regex } { -01 cat =str } loop
  { str "^(.*)</a>(.*)$" regex } { -01 cat =str } loop
  str
} /stripLinkParts deffst

{ [| "/to010.asp?SILFDNR=" -102 |] fetch ":" via
  { "?" ==maybeTitle "?" ==title "?" ==position "?" ==id "?" ==number }'
    _ * =*reset
  [
    { _ ==line stripLinkParts ==strippedLine [
      { line "^<!--[0-9]+ -->" regex }' { maybeTitle iso2utf8 sanitize =title }
      { strippedLine "^(<td>)([^<]+)(</td>|$)" regex }' { "<td>" eq "" maybeTitle ? -01 cat =maybeTitle -- }
      { line "^	*<td class=\"text4\" nowrap=\"nowrap\"><a href=\"[^\"]+\" title=\"[^\"]+\">.&nbsp;([0-9.]+)</a></td>" regex }' {
        =position
      }
      { line "^	*<td class=\"text4\" nowrap=\"nowrap\"><span style=\"background-color:#[^\"]+\" title=\"[^\"]+\"><a href=\"[^\"]+\" title=\"[^\"]+\">.&nbsp;([0-9.]+)</a></span></td>" regex }' {
        =position
      }
      { line "^<td nowrap=\"nowrap\"><a href=\"vo020.asp\\?VOLFDNR=([^\"]+)\">(<b>)?([^<]+)(</b>)?</a></td>" regex }' {
        =id -- =number --
      }
      { line "^	</tr>" regex position "?" neq and }' {
        < number "?" neq ==hasDocument >=id >=number >=title >=position >
        reset
      }
    ] conds } :eachLine :close
  ]
} /agenda deffst

[|
  "<form action=\"do027.asp\" method=\"post\"[^>]*>"
  "<input type=\"hidden\" name=\"DOLFDNR\" value=\"(\\d+)\"[^>]*>"
  "<input type=\"hidden\" name=\"options\" value=\"64\"[^>]*>"
  "<input type=\"hidden\" name=\"typ\" value=\"130\"[^>]*>"
  "<input type=\"submit\" class=\"il2_p\" value=\"Vorlage-Sammeldokument[^\"]*\" title=\"Vorlage-Sammeldokument[^\"]*\"[^>]*>"
  "</form>"
|] enregex =*:DOCUMENTLINKREGEX

{ [| "/vo020.asp?VOLFDNR=" -102 |] _ fetch ":" via
                                     BASEURL -01 cat ==url
  [ {
    DOCUMENTLINKREGEX { _ dump ==id 
      { ==cacheFile
        # grab a session cookie -.-
        {
          [| "wget -O /dev/null --save-cookies '" COOKIES "' --keep-session-cookies '" url "'" |] +shell
        } +spawn "::" via
        { dump } ::err .eachLine ::wait --

        {
          [|
            "wget -O '" cacheFile "' "
            "--load-cookies '" COOKIES "' "
            "'" BASEURL "/do027.asp' "
            "--post-data='DOLFDNR=" id "&options=64&typ=130'"
          |] +shell
        } +spawn "::" via
        { dump } ::err .eachLine ::wait --
      } [| "/document/" id |] cache
    } rep
  } :eachLine :close ] ==docs

  docs len 1 neq {
    <
      { docs { .close } '*0. "/dev/null" open } =*empty
    > ???io.web.pattern
  } rep

  0 docs *
} /fetchDocument deffst

{ ==l { _ len l lt } { "0" -01 cat } loop } '01.0 /padTo deffst

{ ":" via
  [|
    [ :position { _ "^([^.]*)\\.(.*)" regex } { -012 -- } loop ] 3 padTo { "." -201 cat cat } fold
    "_" :number "_"
    :title sanitizeFilename 60 truncateTo
    ".pdf"
  |]
} /agendaFilename deffst

{ # ==year ==month
  calendar { .id "" neq } grep {
    .id agenda { .hasDocument } grep {
      .id fetchDocument .close
    } each
  } each
} /populateCache deffst

{ ==title
  [|
    "<html><head>"
    "<title>" title "</title>"
    "<style type=\"text/css\">"
    "table.agenda td:nth-of-type(2) { min-width: 100px; }"
    "</style>"
    "</head><body><h1>" title "</h1>\n" |]
} /htmlHeader deffst

{
  [| "</body></html>\n" |]
} /htmlFooter deffst

<
  { ==target ==text
    [| "<a href=\"" target "\">" text "</a>" |]
  } /a deffst
  { "<br>" } /br deffst
  { ==items
    [|
      "<ul>"
      items { "<li>" -01 "</li>\n" } each
      "</ul>\n"
    |]
  } /ul deffst
  { ==attrs ==rows
    [|
      "<table" attrs .?class { " class=\"" attrs .class "\"" } rep ">\n"
      rows { ==cols
        "<tr>"
        cols {
          "<td>" -01 "</td>"
        } each
        "</tr>\n"
      } each
      "</table>\n"
    |]
  } /table deffst
> "<>" via

{ "=>" via ==year ==month
  [|
    [| "Sitzungs√ºbersicht " year "-" month |] htmlHeader
    "<table>"
    month year calendar { ":" via
      "<tr>"
        "<td>" :monthday "." month "." year "</td>"
        "<td>" :time :past { " (vergangen)" } rep "</td>"
        "<td>" :title :id "" neq { [| "/agenda/" :id |] <>a } rep "</td>"
      "</tr>"
    } each
    "</table>"
    htmlFooter
  |] =>okHtml
} /showCalendar deffst

{ # ==request
  { [| "date +'%-m %Y'" |] +shell } +spawn ":" via
  4096 :out .read "\n" str .split 0 -01 * :wait --
  " " str .split 2 dearray -102 showCalendar
} /showCurrentCalendar deffst

{
  { [| "date +'%-m %Y'" |] +shell } +spawn ":" via
  4096 :out .read "\n" str .split 0 -01 * :wait --
  " " str .split 2 dearray populateCache

  { [| "date +'%-m %Y' --date='today +1 month'" |] +shell } +spawn ":" via
  4096 :out .read "\n" str .split 0 -01 * :wait --
  " " str .split 2 dearray populateCache
} /populateCurrentCache deffst

{ "=>" via ==id
  [|
    "Tagesordnung" htmlHeader
    [
      id agenda { ":" via
        [
          :position :number
          :title :hasDocument { [| "/editor/" :id |] <>a } rep
        ]
      } each
    ] < /agenda ==class > <>table
    htmlFooter
  |] =>okHtml
} /showAgenda deffst

{ "=>" via ==id
  =>cached VIEWER =>okHtml
} /showEditor deffst

{ "=>" via fetchDocument ":" via
  [|
    { 8192 :read _ "" neq } { } loop :close
  |] =>cached "application/pdf" =>ok
} /showDocument deffst

{ =*p # ==start
  { _ p { _ } rep
      _ .?'children { .children |recurse each } { -- } ? *
  } /recurse deffst
  [ -01 recurse ]
} /selectNodes deffst

{
  [ -01 { ==c
    [
      { c 38 eq }' { "&amp;" { } each }'
      { c 60 eq }' { "&lt;" { } each }'
      { c 62 eq }' { "&gt;" { } each }'
      { 1 }' { c }'
    ] conds
  } each ] str .fromArray
} /escapeXML deffst

{ ==pages ":" via
  "<?xml version=\"1.0\" standalone=\"no\"?>\n" :writeall
  "<xournal version=\"0.4.7\">\n" :writeall
  "<title>Xournal document - see http://math.mit.edu/~auroux/software/xournal/</title>\n" :writeall

  1 ==firstPage
  pages { ==page [|
    "<page width=\"" /width page .attr * "\" height=\"" /height page .attr * "\">\n"
    page { .name "background" eq } selectNodes 0 -01 * ==background
    "<background type=\"pdf\" "
      firstPage {
        0 =firstPage
        "domain=\"" /domain background .attr * "\" filename=\"" /filename background .attr * "\" "
      } rep
      "pageno=\"" /pageno background .attr * "\" "
    "/>\n"
    page { .name "layer" eq } selectNodes { ==layer
      "<layer>\n"
      layer { .name "" neq } selectNodes { ==item
        [
          { item .name "stroke" eq } {
            "<stroke tool=\"" /tool item .attr * "\" color=\"" /color item .attr * "\" width=\"" /width item .attr * "\" user=\"" /user item .attr * "\">"
            item .children { .text } each
            "</stroke>\n"
          }
          { item .name "text" eq } {
            "<text font=\"" /font item .attr *
              "\" size=\"" /size item .attr * "\" x=\"" /x item .attr * "\" y=\"" /y item .attr *
              "\" color=\"" /color item .attr * "\" user=\"" /user item .attr * "\">"
            [| item .children { .text } each |] escapeXML
            "</text>\n"
          }
        ] conds
      } each
      "</layer>\n"
    } each
    "</page>\n"
  |] :writeall } each

  "</xournal>\n" :writeall
} /writeXournal deffst

{ ==pages
  "<?xml version=\"1.0\" standalone=\"no\"?>\n"
  "<xournal version=\"0.4.7\">\n"
  "<title>Xournal document - see http://math.mit.edu/~auroux/software/xournal/</title>\n"

  1 ==firstPage
  pages { ==page [|
    "<page width=\"" /width page .attr * "\" height=\"" /height page .attr * "\">\n"
    page { .name "background" eq } selectNodes 0 -01 * ==background
    "<background type=\"pdf\" "
      firstPage {
        0 =firstPage
        "domain=\"" /domain background .attr * "\" filename=\"" /filename background .attr * "\" "
      } rep
      "pageno=\"" /pageno background .attr * "\" "
    "/>\n"
    page { .name "layer" eq } selectNodes { ==layer
      "<layer>\n"
      layer { .name "" neq } selectNodes { ==item
        [
          { item .name "stroke" eq } {
            "<stroke tool=\"" /tool item .attr * "\" color=\"" /color item .attr * "\" width=\"" /width item .attr * "\">"
            item .children { .text } each
            "</stroke>\n"
          }
          { item .name "text" eq } {
            "<text font=\"" /font item .attr *
              "\" size=\"" /size item .attr * "\" x=\"" /x item .attr * "\" y=\"" /y item .attr *
              "\" color=\"" /color item .attr * "\">"
            [| item .children { .text } each |] escapeXML
            "</text>\n"
          }
        ] conds
      } each
      "</layer>\n"
    } each
    "</page>\n"
  |] } each

  "</xournal>\n"
} /exportXournal deffst

{ "=>" via ==id [| "/comments/" id |] ==identifier
  "Adding comment" dump
  =>args .page dump
  =>body dump

  # FIXME: input validation .page, .width, .height, .user (must exist and have valid format)
  =>args .page txt .consume .u ==changedPage

  [
    { =>body "<stroke tool=\"([^\"]+)\" color=\"([^\"]+)\" width=\"([0-9.]+)\">(\n[0-9. ]+\n)</stroke>" regex } {
      <
        "stroke" ==name map ==attr
        /tool attr =[]
        /color attr =[]
        /width attr =[]
        =>args .user /user attr =[]

        < "" ==name ==text > [ -01 ] ==children
      >
    }
    { =>body "<text font=\"Sans\" size=\"12.00\" x=\"([0-9]+)[^\"]*\" y=\"([0-9]+)[^\"]*\" color=\"([^\"]+)\">(([^<>&]|&lt;|&gt;|&amp;)+)</text>" regex } {
      <
        "text" ==name map ==attr
        "Sans" /font attr =[]
        "12.00" /size attr =[]
        /x attr =[]
        /y attr =[]
        /color attr =[]
        =>args .user /user attr =[]

        < "" ==name ==text -- > [ -01 ] ==children
      >
    }
    { 1 } {
      "Invalid body - ignoring request." dump
      < "" ==name "" ==text >
    }
  ] conds ==newElement

  { ==cacheFile
    sys .file ":" via :creating :writeonly cacheFile :open
    EMPTYXOJ :writeall
    :close
  } identifier comments ":" via
  
  [|
    { 8192 :read _ "" neq } { } loop :close
  |] xml .parse { .name "page" eq } selectNodes ==pages

  pages dump

  { pages len changedPage lt } {
    pages [
      <
        "page" ==name map ==attr
        =>args .width /width attr =[] # FIXME: get this number from somewhere
        =>args .height /height attr =[] # FIXME: get this number from somewhere
        [
          <
            "background" ==name map ==attr
            "pdf" /type attr =[]
            pages len 1 add txt .produce .u /pageno attr =[]
            pages len not {
              "absolute" /domain attr =[]
              "/dev/null" /filename attr =[]
            } rep
          >
          <
            "layer" ==name map ==attr
            [ < "" ==name "" ==text map ==attr > ] ==children
            { =children } =*setChildren
          >
        ] ==children
      >
    ] cat =pages
  } loop

  changedPage 1 sub pages * { .name "layer" eq } selectNodes 0 -01 * _ .children [ newElement ] cat
                                                                       -01 .setChildren

  identifier commentsFilename ==storageFile
  "Rewriting: " storageFile cat dump
  [| storageFile "." ++getpid txt .produce .u cat |] ==newFilename
  sys .file _ ":" via :truncating :creating :writeonly newFilename :open
              pages writeXournal :close

  newFilename storageFile +rename

  "Added." "text/plain" =>ok
} /addComments deffst

{ "=>" via ==id [| "/comments/" id |] ==identifier
  "Removing comment" dump
  =>args .page dump
  =>body dump

  # FIXME: input validation .page, .width, .height, .user (must exist and have valid format)
  =>args .page txt .consume .u ==changedPage

  [
    { =>body "<stroke tool=\"([^\"]+)\" color=\"([^\"]+)\" width=\"([0-9.]+)\">(\n[0-9. ]+\n)</stroke>" regex } {
      <
        "stroke" ==name map ==attr
        /tool attr =[]
        /color attr =[]
        /width attr =[]
        =>args .user /user attr =[]

        < "" ==name ==text > [ -01 ] ==children
      >
    }
    { =>body "<text font=\"Sans\" size=\"12.00\" x=\"([0-9]+)[^\"]*\" y=\"([0-9]+)[^\"]*\" color=\"([^\"]+)\">(([^<>&]|&lt;|&gt;|&amp;)+)</text>" regex } {
      <
        "text" ==name map ==attr
        "Sans" /font attr =[]
        "12.00" /size attr =[]
        /x attr =[]
        /y attr =[]
        /color attr =[]
        =>args .user /user attr =[]

        < "" ==name ==text -- > [ -01 ] ==children
      >
    }
    { 1 } {
      "Invalid body - ignoring request." dump
      < "" ==name "" ==text >
    }
  ] conds ==removedElement

  { ==cacheFile
    sys .file ":" via :creating :writeonly cacheFile :open
    EMPTYXOJ :writeall
    :close
  } identifier comments ":" via
  
  [|
    { 8192 :read _ "" neq } { } loop :close
  |] xml .parse { .name "page" eq } selectNodes ==pages

  pages dump

  { ==e
    e .name removedElement .name eq {
      1
      removedElement .attr dom { ==k
        k e .attr .has {
          k e .attr * k removedElement .attr * neq { -- 0 } rep
        } { -- 0 } ? *
      } each
      e .?children {
        removedElement .?children {
          e removedElement { .children 0 -01* .text } -20*10* neq { -- 0 } rep
        } { -- 0 } ? *
      } rep
    } { 0 } ? *
  } /isRemovedElement deffst

  pages len changedPage ge {
    changedPage 1 sub pages * { .name "layer" eq } selectNodes 0 -01 * _ .children { isRemovedElement not } grep
                                                                         -01 .setChildren

    identifier commentsFilename ==storageFile
    "Rewriting: " storageFile cat dump
    [| storageFile "." ++getpid txt .produce .u cat |] ==newFilename
    sys .file _ ":" via :truncating :creating :writeonly newFilename :open
                pages writeXournal :close

    newFilename storageFile +rename
  } rep

  "Removed." "text/plain" =>ok
} /removeComments deffst

{ "=>" via ==id
  [| "/comments/" id |] ==identifier
  identifier commentsFilename fileExists {
    { "Comments file should have existed." die } identifier comments ":" via

    [|
      { 8192 :read _ "" neq } { } loop :close
    |] xml .parse { .name "page" eq } selectNodes ==pages

    [| pages exportXournal |]
  } {
    EMPTYXOJ
  } ? *
  "application/xournal" =>ok
} /showComments deffst

{ "=>" via
  [|
    "Seite nicht gefunden" htmlHeader
    "Diese Seite existiert nicht"
    htmlFooter
  |] =>failHtml
} /showNotFound deffst

{ open ":" via
  [| { 8192 :read _ "" neq } { } loop :close |]
} /slurp deffd

"pdf.js" slurp ==:PDFJS
"pdf.worker.js" slurp ==:PDFJSWORKER
"pdf.js.upstream/build/generic/web/compatibility.js" slurp ==:COMPATIBILITYJS
"pdf.js.upstream/build/generic/web/l10n.js" slurp ==:LOCALIZATIONJS
"viewer.properties" slurp ==:LOCALE
"viewer.js" slurp ==:VIEWERJS
"viewer.css" slurp ==:VIEWERCSS
"viewer.html" slurp ==:VIEWER
map ==:PNGS map ==:GIFS
"pdf.js.upstream/build/generic/web/images/*.png" sys .glob { _ dump ==img
  img slurp "pdf.js.upstream/build/generic/web" len img str .postfix PNGS =[]
} each
"pdf.js.upstream/build/generic/web/images/*.gif" sys .glob { _ dump ==img
  img slurp "pdf.js.upstream/build/generic/web" len img str .postfix GIFS =[]
} each

"test.pdf.xoj.gunz" slurp ==:XOJ
"empty.xoj.gunz" slurp ==:EMPTYXOJ
"erase.png" slurp "/erase.png" PNGS =[]

{
  net .alg .httpServer "+" via
  { 8092 } +port
  {
    <
      { "text/html; charset=utf-8;" ok } =*okHtml
      { "text/html; charset=utf-8;" fail } =*failHtml
      { "Cache-Control: max-age=3600" addHeader } =*cached
    >' _ ":_" defvst ":" via

    :url dump
    [
      { :url "/" eq } { :_ showCurrentCalendar }
      { :url "^/(\\d\\d\\d\\d)-(\\d\\d?)" regex } { :_ showCalendar }
      { :url "^/agenda/(\\d+)$" regex } { :_ showAgenda }
      { :url "^/editor/(\\d+)$" regex } { :_ showEditor }
      { :url "^/editor/(\\d+).pdf$" regex } { :_ showDocument }
      { :url "^/editor/(\\d+).xoj$" regex } { :_ showComments }
      { :url "^/document/(\\d+)$" regex } { :_ showDocument }
      { :url "^/comments/(\\d+)/add$" regex } { :_ addComments }
      { :url "^/comments/(\\d+)/remove$" regex } { :_ removeComments }
      { :url "^/comments/(\\d+)$" regex } { :_ showComments }
      { :url "/pdf.js" eq } { PDFJS :cached "text/javascript; charset=utf-8;" :ok }
      { :url "/pdf.worker.js" eq } { PDFJSWORKER :cached "text/javascript; charset=utf-8;" :ok }
      { :url "/compatibility.js" eq } { COMPATIBILITYJS :cached "text/javascript; charset=utf-8;" :ok }
      { :url "/l10n.js" eq } { LOCALIZATIONJS :cached "text/javascript; charset=utf-8;" :ok }
      { :url "/locale.properties" eq } { LOCALE :cached "application/l10n" :ok }
      { :url "/viewer.js" eq } { VIEWERJS :cached "text/javascript; charset=utf-8;" :ok }
      { :url "/viewer.css" eq } { VIEWERCSS :cached "text/css; charset=utf-8;" :ok }
      { :url PNGS .has } { :url PNGS * :cached "image/png" :ok }
      { :url GIFS .has } { :url GIFS * :cached "image/gif" :ok }
      { :url "^/precache/(\\d\\d\\d\\d)-(\\d\\d?)" regex } { populateCache "Cached." "text/plain" :ok }
      { :url "/precache" eq } { populateCurrentCache "Cached." "text/plain" :ok }
      { 1 } { :_ showNotFound }
    ] conds
  } +request
  { 64 1024 1024 mul mul } +outputBufferLimit
  { 1024 1024 mul } +inputBufferLimit
  { -- ++fork -- ++fork -- } +afterListen
  +run
} /forallris sys .freeze

# vim: syn=elymas
